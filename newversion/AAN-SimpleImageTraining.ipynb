{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd87a20c-c682-4dd3-bc4d-9caba0ce479e",
   "metadata": {},
   "source": [
    "# Artificial Association Neural Networks\n",
    "## This notebook covers only a basic image training process for understanding AAN.\n",
    "\n",
    "<img src=\"img/Fig3.png\" width=\"700\" height=\"200\"/>\n",
    "<!-- \n",
    "![n1](img/Fig3.png)\n",
    " -->\n",
    "\n",
    "This neural network goes through the following three steps:\n",
    "\n",
    "1. Feature extraction from each domain\n",
    "2. Association of the extracted features\n",
    "3. Utilization of the associated information to perform various subtasks and a main task\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e164f437-d318-40ad-a859-d90b0f2e2131",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.artificial_association_networks import ArtificialAssociationNeuralNetworks\n",
    "from data_structures.neurodataloader import NeuroDataset, createNeuroDataloader\n",
    "from data_structures.neuronode import NeuroNode\n",
    "from data_structures.batch_neurotree import BatchNeuroTree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116c1f78-5552-47cc-b9c0-39534ed60269",
   "metadata": {},
   "source": [
    "\n",
    "## If the current device is not in CUDA mode and is using CPU, please modify the config/options.py file in the config directory.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fed813d-e44e-4d6c-a021-93290f0d5036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device :  cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "print('Device : ', device)\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb0507c0-020d-4cac-a57b-fe5aa8ffaa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from config.option import device\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29392cc-13b1-4e45-87ce-9bf20b25caf9",
   "metadata": {},
   "source": [
    "## The key idea of this neural network model is to generalize the learning process for any given data without altering the structure of the neural network model. \n",
    "![n2](img/Fig4.png)\n",
    "#### In other words, the goal is to implement a model that can embed any arbitrary X as a hidden state (h), and NeuroNode and NeuroTree are data structures that allow for varying the number of convolutions and the structure of layers in the neural network model based on the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d4e5fb-8305-4949-b44b-6a0a692d837f",
   "metadata": {},
   "source": [
    "<img src=\"img/Fig5a.png\" width=\"130\" height=\"130\"/>\n",
    "On the left is a multi-layer perceptron structure, and on the right is a NeuroTree structure.\n",
    "\n",
    "<img src=\"img/Fig5b.png\" width=\"350\" height=\"150\"/> \n",
    "On the left is a Recurrent Neural Network structure, and on the right is a NeuroTree structure.\n",
    "\n",
    "<img src=\"img/Fig5c.png\" width=\"300\" height=\"150\"/> \n",
    "On the left is a Recursive Neural Network (RvNN) structure, and on the right is a NeuroTree structure.\n",
    "\n",
    "<img src=\"img/Fig5d.png\" width=\"300\" height=\"130\"/> \n",
    "On the left is a Convolutional Neural Network (CNN) structure, and on the right is a NeuroTree structure.\n",
    "\n",
    "<img src=\"img/Fig5e.png\" width=\"300\" height=\"130\"/>\n",
    "On the left is a Graph Neural Network (GNN) structure, and on the right is a NeuroTree structure.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c126b576-fb37-4696-9cd3-658e4cad43a9",
   "metadata": {},
   "source": [
    "### In addition to the above-mentioned structures, NeuroTree also allows for connections that pass information beyond the layers.\n",
    "\n",
    "<img src=\"img/Fig5f.png\" width=\"300\" height=\"150\"/> <img src=\"img/Fig5g.png\" width=\"200\" height=\"150\"/> \n",
    "\n",
    "The details are in the paper.\n",
    "\n",
    "<!-- ![n7](img/Fig5e.png)\n",
    "![n8](img/Fig5f.png)\n",
    " -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14be0b1-5b2e-4061-abf7-ba1776f0cca6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bf5b47-7974-4cb6-85d1-2591206d246b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4bec8fc5-dc9a-4ae1-9858-1e7a4d199a67",
   "metadata": {},
   "source": [
    "### 1: Defining DataLoader and Neurotree Builder Functions\n",
    "\n",
    "In this chapter, we will define the DataLoader and Neurotree Builder functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b94f0880-ba70-4eaf-accb-143cb657279e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datas.image.load import MNIST_DATA\n",
    "\n",
    "\n",
    "image_train, image_test = MNIST_DATA('./datas/image') # image CNN\n",
    "\n",
    "todataset=lambda o: o.dataset\n",
    "image_train, image_valid = torch.utils.data.random_split(image_train, [50000, 10000])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e802c320-3532-4990-a94b-462323b55533",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = {\n",
    "    'image' : image_train.dataset.data[image_train.indices].unsqueeze(1)\n",
    "}\n",
    "\n",
    "train_y = {\n",
    "    'image' : image_train.dataset.targets[image_train.indices]\n",
    "}\n",
    "\n",
    "valid_x = {\n",
    "    'image' : image_valid.dataset.data[image_valid.indices].unsqueeze(1)\n",
    "}\n",
    "\n",
    "valid_y = {\n",
    "    'image' : image_valid.dataset.targets[image_valid.indices]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "test_x = {\n",
    "    'image' : image_test.data.unsqueeze(1)\n",
    "}\n",
    "\n",
    "test_y = {\n",
    "    'image' : image_test.targets\n",
    "}\n",
    "\n",
    "\n",
    "maintask_map = {\n",
    "    'image' : 'classification'\n",
    "}\n",
    "\n",
    "\n",
    "# neurotree building \n",
    "def image2neurotree(data, mt):\n",
    "    leaf = NeuroNode(data.to(device, dtype=torch.float)/255, 'image', None, None, [])\n",
    "    node = NeuroNode(None, None, None, None, [])\n",
    "    node.insert(leaf)\n",
    "    root = NeuroNode(None, None, None, None, [])\n",
    "    root.insert(node) \n",
    "    return root\n",
    "\n",
    "\n",
    "\n",
    "# data -> neurotree\n",
    "xmt2neurotree = {\n",
    "    'image' : image2neurotree\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8669c516-75b9-4dff-89cc-dc1bdb548842",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = NeuroDataset(train_x, train_y, maintask_map, xmt2neurotree)\n",
    "valid_dataset = NeuroDataset(valid_x, valid_y, maintask_map, xmt2neurotree)\n",
    "test_dataset = NeuroDataset(test_x, test_y, maintask_map, xmt2neurotree)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2570b170-2794-48bb-bc55-ff8d1dc6d9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = createNeuroDataloader(train_dataset, batch_size=100, prefetch_factor=None)\n",
    "valid_dataloader = createNeuroDataloader(valid_dataset, batch_size=100, prefetch_factor=None)\n",
    "test_dataloader = createNeuroDataloader(test_dataset, batch_size=100, prefetch_factor=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e4b8ee-5253-46a8-9f90-135a0c74d1c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddadcd8-b583-408f-a091-93d6bf7551ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175eb4fd-b65a-487f-96b7-c53aa5f031ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1617d025-c0c1-4a5b-b780-0f809f2b3dd7",
   "metadata": {},
   "source": [
    "### 2: Defining Feature Extraction Models\n",
    "\n",
    "In this chapter, we will define the Feature Extraction Models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5f569cf-900c-4fc0-a0f9-c190b60b349a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LeNet_5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, stride=1)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1)\n",
    "        self.conv3 = nn.Conv2d(16, 120, kernel_size=4, stride=1)\n",
    "        self.parameter_init()\n",
    "\n",
    "    def parameter_init(self):\n",
    "        for param in self.parameters():\n",
    "            if len(param.shape) > 1:\n",
    "                nn.init.xavier_uniform_(param, gain=1.414)\n",
    "\n",
    "    def forward(self, batch_tree: BatchNeuroTree):\n",
    "        batch_x = batch_tree.getX()\n",
    "        x = torch.stack(batch_x).to(device, dtype = torch.float)\n",
    "\n",
    "        x = F.tanh(self.conv1(x))\n",
    "        x = F.avg_pool2d(x, 2, 2)\n",
    "        x = F.tanh(self.conv2(x))\n",
    "        x = F.avg_pool2d(x, 2, 2)\n",
    "        x = F.tanh(self.conv3(x))\n",
    "        x = x.view(-1, 120)\n",
    "        zeros = torch.zeros(x.shape[0], 8).to(device)\n",
    "        out = torch.cat([x, zeros], dim=-1)\n",
    "        return out\n",
    "\n",
    "    def setting_pretrained_model(self, model):\n",
    "        self.conv1 = model.conv1\n",
    "        self.conv2 = model.conv2\n",
    "        self.conv3 = model.conv3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e59d7e13-8563-4021-b2c5-38409287a056",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image2vec = LeNet_5().to(device)\n",
    "\n",
    "fe_networks = {\n",
    "    # 'class': astcls2vec,\n",
    "    # 'Num': astnum2vec,\n",
    "    'image' : image2vec\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3eb133-a865-4f98-9c1d-ed385e011918",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3decc6b3-67b8-4a49-bfad-33f2e1647a27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c3e9a95-0611-4f97-8af4-e39f14fc9160",
   "metadata": {},
   "source": [
    "### 3: Defining Subtasks and Maintask\n",
    "\n",
    "In this chapter, we will define the subtasks and maintask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ced15c10-79dd-49c9-bb84-02ab0f032e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classification(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim, class_count):\n",
    "        super().__init__()\n",
    "        self.task_name = 'classification'\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.class_count = class_count\n",
    "\n",
    "        self.loss_function = torch.nn.NLLLoss()\n",
    "\n",
    "\n",
    "        self.recognition_layer = nn.Sequential(\n",
    "            nn.Linear(self.hidden_dim, class_count),\n",
    "            nn.LogSoftmax(dim=-1)\n",
    "            #                     nn.Softmax(dim = 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, hiddens, tree):\n",
    "        if type(hiddens) == list:\n",
    "            hiddens = torch.stack(hiddens, dim = 0)\n",
    "        outputs = self.recognition_layer(hiddens)\n",
    "        return outputs\n",
    "\n",
    "    def loss(self,batch_domains, batch_outputs, batch_targets):\n",
    "        # corrects = 0\n",
    "        preds = torch.stack(batch_outputs, dim = 0)\n",
    "        targets = torch.stack(batch_targets, dim=0).to(device, dtype = torch.long)\n",
    "\n",
    "        # print('loss',preds.shape, targets.shape)\n",
    "\n",
    "        corrects = defaultdict(int)\n",
    "        counts = defaultdict(int)\n",
    "\n",
    "\n",
    "        loss = self.loss_function(preds, targets)\n",
    "        _, predictions = torch.max(preds, 1)\n",
    "\n",
    "        for domain, label, prediction in zip(batch_domains, targets, predictions):\n",
    "            if label == prediction:\n",
    "                corrects[domain] += 1\n",
    "            counts[domain] += 1\n",
    "        return loss, corrects, counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "764d54c0-3dc1-485d-b200-9a6b43362e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# sub_classification = Classification(128, 70).to(device)\n",
    "subtask_networks = {\n",
    "    # 'parent_pred': sub_classification\n",
    "}\n",
    "\n",
    "main_classification = Classification(128, 10).to(device)\n",
    "# self.main_autoencoder = AutoEncoder(128, self.dran).to(device)\n",
    "maintask_networks = {\n",
    "    'classification': main_classification,\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424c381a-4cb5-4dad-8f92-7b6eb9c9f863",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d316bba6-6cb3-4a27-ac9e-b5ab812463f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81608f31-2e30-4047-89c3-0cd76d437e4e",
   "metadata": {},
   "source": [
    "### 4: Defining Artificial Association Networks (AAN)\n",
    "\n",
    "In this chapter, we will define the Artificial Association Networks (AAN), which integrate the models defined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0be50b90-9567-4d55-8104-e8c696147d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "aan_model = ArtificialAssociationNeuralNetworks(\n",
    "    128, 128,\n",
    "    fe_networks, {}, \n",
    "    subtask_networks, maintask_networks,    \n",
    "    version='gaau').to(device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f022b889-3127-47e7-b25c-3d4070395693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wandb\n",
    "# import random\n",
    "\n",
    "# lr = 0.02\n",
    "# model_name = \"GAAU-128-128\"\n",
    "# dataset = \"MNIST\"\n",
    "# epochs = 10\n",
    "\n",
    "# # start a new wandb run to track this script\n",
    "# wandb.init(\n",
    "#     # set the wandb project where this run will be logged\n",
    "#     project=\"artificial-association-networks-test\",\n",
    "    \n",
    "#     # track hyperparameters and run metadata\n",
    "#     config={\n",
    "#     \"learning_rate\": lr,\n",
    "#     \"architecture\": model_name,\n",
    "#     \"dataset\": dataset,\n",
    "#     \"epochs\": epochs,\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6caf84-b659-4d88-a58b-9b5344adb611",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "274e45e7-ba58-47da-b115-575e77d57745",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "101b7355-b270-47da-8370-b39029c5b675",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PylightningArtificialAssociationNeuralNetworks(pl.LightningModule):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.training_result = 0\n",
    "        self.training_count = 0\n",
    "        self.training_loss = 0\n",
    "        self.valid_result = 0\n",
    "        self.valid_count = 0\n",
    "        self.valid_loss = 0\n",
    "        \n",
    "        self.model = model\n",
    "\n",
    "\n",
    "    def forward(self, data, mt):\n",
    "        return self.aan(data, mt, node_level = True)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y, mt, domain = batch\n",
    "        maintask_outputs, h_root, batchNeuroTree = self.model(x, mt)\n",
    "        y_hat = torch.stack(maintask_outputs, dim = 0)\n",
    "        y_target = torch.stack(y, dim = 0)\n",
    "\n",
    "        loss = F.cross_entropy(y_hat, y_target)\n",
    "        \n",
    "        predictions = torch.argmax(y_hat, 1)\n",
    "        pred = torch.sum(predictions == y_target)\n",
    "        self.training_result += pred.item()\n",
    "        self.training_count += len(y)\n",
    "        self.training_loss += loss.item()\n",
    "\n",
    "        \n",
    "        # logs metrics for each training_step,\n",
    "        # and the average across the epoch, to the progress bar and logger\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        # training_step_outputs has all my batches\n",
    "\n",
    "        if self.training_count != 0:\n",
    "            print('[Training]', (self.training_result, self.training_count), self.training_result/self.training_count)\n",
    "        if self.valid_count != 0:\n",
    "            print('[Validation]', (self.valid_result, self.valid_count), self.valid_result/self.valid_count)\n",
    "        # wandb.log(\n",
    "        #     {\n",
    "        #     \"acc\": self.training_result/self.training_count, \n",
    "        #     \"val\": self.valid_result/self.valid_count,\n",
    "        #     \"training_loss\" : self.training_loss,\n",
    "        #     \"valid_loss\" : self.valid_loss\n",
    "        #     }\n",
    "        # )\n",
    "        self.training_result = 0\n",
    "        self.training_count = 0\n",
    "        self.training_loss = 0\n",
    "        self.valid_result = 0\n",
    "        self.valid_count = 0            \n",
    "        self.valid_loss = 0\n",
    "        \n",
    "        return\n",
    "            \n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y, mt, domain = batch\n",
    "        maintask_outputs, h_root, batchNeuroTree = self.model(x, mt)\n",
    "        y_hat = torch.stack(maintask_outputs, dim = 0)\n",
    "        y_target = torch.stack(y, dim = 0)\n",
    "\n",
    "        loss = F.cross_entropy(y_hat, y_target)\n",
    "        predictions = torch.argmax(y_hat, 1)\n",
    "        pred = torch.sum(predictions == y_target)\n",
    "        self.valid_result += pred.item()\n",
    "        self.valid_count += len(y)\n",
    "        self.valid_loss += loss.item()\n",
    "\n",
    "        return pred        \n",
    "   \n",
    "    \n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y, mt, domain = batch\n",
    "        maintask_outputs, h_root, batchNeuroTree = self.model(x, mt)\n",
    "        y_hat = torch.stack(maintask_outputs, dim = 0)\n",
    "        y_target = torch.stack(y, dim = 0)\n",
    "        predictions = torch.argmax(y_hat, 1)\n",
    "        pred = torch.sum(predictions == y_target)\n",
    "        return pred\n",
    "        \n",
    "\n",
    "            \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89c88aeb-7017-4ef5-a00d-c4ed6e79c558",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyaan = PylightningArtificialAssociationNeuralNetworks(aan_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1f7a7f1-bcc9-4b73-9cb2-20e59e844c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134415"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "count_parameters(main_classification)\n",
    "count_parameters(aan_model.multi_main_task_networks), count_parameters(aan_model.multi_sub_task_networks)\n",
    "\n",
    "\n",
    "count_parameters(aan_model.multi_feature_extraction_networks), count_parameters(aan_model.multi_restoration_networks)\n",
    "\n",
    "count_parameters(aan_model.ran.rnn.X2H)\n",
    "\n",
    "count_parameters(aan_model.ran.rnn.H2H)\n",
    "count_parameters(aan_model.ran.rnn)\n",
    "count_parameters(aan_model.ran.gnn)\n",
    "count_parameters(aan_model.ran)\n",
    "count_parameters(aan_model.multi_feature_extraction_networks)\n",
    "count_parameters(pyaan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d39d16-dee0-4117-a9e4-3eb28f6a9dde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dfd118b8-5d9f-41ad-85ac-dbb129670b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type                                | Params\n",
      "--------------------------------------------------------------\n",
      "0 | model | ArtificialAssociationNeuralNetworks | 134 K \n",
      "--------------------------------------------------------------\n",
      "134 K     Trainable params\n",
      "0         Non-trainable params\n",
      "134 K     Total params\n",
      "0.538     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bigedu/miniconda3/envs/mytorch/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/bigedu/miniconda3/envs/mytorch/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a3dc5bbe9134c67afae9646e3f6ba17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bigedu/miniconda3/envs/mytorch/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:76: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training] (42354, 50000) 0.84708\n",
      "[Validation] (9209, 10200) 0.902843137254902\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training] (46851, 50000) 0.93702\n",
      "[Validation] (9438, 10000) 0.9438\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training] (47670, 50000) 0.9534\n",
      "[Validation] (9556, 10000) 0.9556\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training] (48151, 50000) 0.96302\n",
      "[Validation] (9626, 10000) 0.9626\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training] (48441, 50000) 0.96882\n",
      "[Validation] (9665, 10000) 0.9665\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training] (48641, 50000) 0.97282\n",
      "[Validation] (9700, 10000) 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training] (48764, 50000) 0.97528\n",
      "[Validation] (9726, 10000) 0.9726\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training] (48878, 50000) 0.97756\n",
      "[Validation] (9749, 10000) 0.9749\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training] (48971, 50000) 0.97942\n",
      "[Validation] (9762, 10000) 0.9762\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training] (49038, 50000) 0.98076\n",
      "[Validation] (9773, 10000) 0.9773\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs = 10)\n",
    "trainer.fit(pyaan, train_dataloader, valid_dataloader)\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc58bc5c-efdc-4b80-ac5d-27a77382af9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mytorch",
   "language": "python",
   "name": "mytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
